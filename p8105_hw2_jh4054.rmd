---
title: "p8105_hw2_jh4054"
author: "Joy Hsu"
date: "10/4/2018"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: show
---

This R Markdown for hw2 reinforces skills from Data Wrangling.

### Setup

Load packages and set specifications for visual outputs
```{r setup, collapse=TRUE}
#load packages
library(tidyverse)
library(ggridges)
library(janitor)
library(readxl)
library(patchwork)

#set output specifications for visuals
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

### Problem 1

Read & clean NYC Transit Subway dataset
```{r, collapse=TRUE}

nyc_trans = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

The NYC Transit dataset describes parameters for each entry and exit point in every NYC subway station. Details for each location include coordinates, routes served, vending, staffing, and ADA compliance. Initial cleaning involved 1) changing variable names to snake case, 2) mutating the `entry` variable from a character to a logical variable: `TRUE` for the presence of an entry and `FALSE` for no entry. Additionally, only select variables of interest were retained: line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. The initial dataset was untidy; each route number was listed as a separate column variable. After abovementioned cleaning steps, the dimensions of the resulting dataset is (`r dim(nyc_trans)`)

Further details:

1. There are 465 distinct stations, identified by name and line
2. There are 84 ADA compliant stations
3. 38% of station entrances/exits without vending allow entrance

```{r, collapse=TRUE}
#dimensions
dim(nyc_trans)

#1. number of distinct stations, identified by name and line
distinct(nyc_trans, line, station_name) %>% 
  nrow()

#2. number of ADA compliant stations
nyc_trans %>% 
  filter(ada == TRUE) %>%
  distinct(line, station_name) %>% 
  nrow()

#3. proprotion of station entrances/exits without vending that allow entrance
nrow(
  filter(nyc_trans, vending == "NO" & entry == "TRUE")) /
nrow(
  filter(nyc_trans, vending == "NO"))
```

Next, we address the untidy variables by gathering the route number columns. There are 60 stations that serve the A train, of which 17 are ADA compliant.
```{r, collapse=TRUE}
#Reformat data so that route number and route name are distinct variables
nyc_trans_tidy = nyc_trans %>% 
  gather(key = route_number, value = route_name, route1:route11, na.rm = TRUE) %>% 
  separate(route_number, into = c("rem1", "route_number"), sep = 5) %>% 
  select(-rem1)

#1. number of distinct stations that serve the A train. 
nyc_trans_tidy %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name) %>%
  nrow()

#2. number of ADA compliant stations that serve the A train
nyc_trans_tidy %>% 
  filter(route_name == "A", ada == TRUE) %>% 
  distinct(line, station_name) %>% 
  nrow()
```

### Problem 2

Read and clean `trash_wheel` data
```{r, collapse=TRUE}
trash_wheel = readxl::read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 1, range = "A2:N338") %>% 
  janitor::clean_names() %>% 
  filter(dumpster != "NA") %>% 
  mutate(month = tolower(month)) %>% 
  mutate(sports_balls = as.integer(round(sports_balls, digits = 0)))
```

Read and clean precipitation data for 2016 and 2017. Join datasets for 2016 and 2017. 
```{r, collapse=TRUE}
#read and clean precipitation data for 2016
precip_2016 = readxl::read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 5, range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(
    month = month.abb[month], 
    month = tolower(month),
    year = 2016) %>% 
  rename(prcp_inches = total)

#read and clean precipitation data for 2016
precip_2017 = readxl::read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 4, range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(
    month = month.abb[month], 
    month = tolower(month),
    year = 2017) %>% 
  rename(prcp_inches = total)

#combine data for 2016 & 2017
precip_years = bind_rows(precip_2016, precip_2017)
```

####Mr. Trash Wheel

1. sum of precipitation in 2017 = 32.93 inches
2. median sports_balls in 2016 = 26

```{r, collapse=TRUE}
#total precipitation in 2017
sum(precip_2017$prcp_inches)

#median number of sports balls in a dumpster in 2016
trash_wheel %>% 
  group_by(year) %>% 
  summarise(
    sports_balls = median(sports_balls),
    glass_bottles = mean(glass_bottles),
    plastic_bottles = mean(plastic_bottles),
    polystyrene = mean(polystyrene), 
    chip_bags = mean(chip_bags))
```

### Problem 3

Load BRFSS dataset
```{r, collapse=TRUE}
library(p8105.datasets)

data(brfss_smart2010)
```

Clean BRFSS dataset
```{r}
brfss = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  select(-class, -topic, -question, -sample_size, -c(confidence_limit_low:geo_location)) %>% 
  separate(locationdesc, into = c("rem1", "county"), sep = 5) %>% 
  select(-rem1) %>% 
  rename(state = locationabbr) %>% 
  spread(key = response, value = data_value) %>%
  janitor::clean_names() %>% 
  select(year, state, county, poor, fair, good, very_good, excellent) %>% 
  arrange(year, state, county)
```






