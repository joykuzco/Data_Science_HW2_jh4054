---
title: "p8105_hw2_jh4054"
author: "Joy Hsu"
date: "10/4/2018"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: show
---

This R Markdown for hw2 reinforces skills from Data Wrangling.

### Setup

Load packages and set specifications for visual outputs
```{r setup, collapse=TRUE}
#load packages
library(tidyverse)
library(ggridges)
library(janitor)
library(readxl)
library(patchwork)

#set output specifications for visuals
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

### Problem 1

Read & clean NYC Transit Subway dataset
```{r, collapse=TRUE}

nyc_trans = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

The NYC Transit dataset describes parameters for each entry and exit point in every NYC subway station. Details for each location include coordinates, routes served, vending, staffing, and ADA compliance. Initial cleaning involved 1) changing variable names to snake case, 2) mutating the `entry` variable from a character to a logical variable: `TRUE` for the presence of an entry and `FALSE` for no entry. Additionally, only select variables of interest were retained: line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. The initial dataset was untidy; each route number was listed as a separate column variable. After abovementioned cleaning steps, the dimensions of the resulting dataset is (`r dim(nyc_trans)`)

Further details:

1. There are 465 distinct stations, identified by name and line
2. There are 84 ADA compliant stations
3. 38% of station entrances/exits without vending allow entrance

```{r, collapse=TRUE}
#dimensions
dim(nyc_trans)

#1. number of distinct stations, identified by name and line
distinct(nyc_trans, line, station_name) %>% 
  nrow()

#2. number of ADA compliant stations
nyc_trans %>% 
  filter(ada == TRUE) %>%
  distinct(line, station_name) %>% 
  nrow()

#3. proprotion of station entrances/exits without vending that allow entrance
nrow(
  filter(nyc_trans, vending == "NO" & entry == "TRUE")) /
nrow(
  filter(nyc_trans, vending == "NO"))
```

Next, we address the untidy variables by gathering the route number columns. There are 60 stations that serve the A train, of which 17 are ADA compliant.
```{r, collapse=TRUE}
#Reformat data so that route number and route name are distinct variables
nyc_trans_tidy = nyc_trans %>% 
  gather(key = route_number, value = route_name, route1:route11, na.rm = TRUE) %>% 
  separate(route_number, into = c("rem1", "route_number"), sep = 5) %>% 
  select(-rem1)

#1. number of distinct stations that serve the A train. 
nyc_trans_tidy %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name) %>%
  nrow()

#2. number of ADA compliant stations that serve the A train
nyc_trans_tidy %>% 
  filter(route_name == "A", ada == TRUE) %>% 
  distinct(line, station_name) %>% 
  nrow()
```

### Problem 2

Read and clean `trash_wheel` data
```{r, collapse=TRUE}
trash_wheel = readxl::read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 1, range = "A2:N338") %>% 
  janitor::clean_names() %>% 
  filter(dumpster != "NA") %>% 
  mutate(month = tolower(month)) %>% 
  mutate(sports_balls = as.integer(round(sports_balls, digits = 0)))
```

Read and clean precipitation data for 2016 and 2017. Join datasets for 2016 and 2017. 
```{r, collapse=TRUE}
#read and clean precipitation data for 2016
precip_2016 = readxl::read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 5, range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(
    month = month.abb[month], 
    month = tolower(month),
    year = 2016) %>% 
  rename(prcp_inches = total)

#read and clean precipitation data for 2016
precip_2017 = readxl::read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 4, range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(
    month = month.abb[month], 
    month = tolower(month),
    year = 2017) %>% 
  rename(prcp_inches = total)

#combine data for 2016 & 2017
precip_years = bind_rows(precip_2016, precip_2017)
```

####Mr. Trash Wheel

1. sum of precipitation in 2017 = 32.93 inches
2. median sports_balls in 2016 = 26

```{r, collapse=TRUE}
#total precipitation in 2017
sum(precip_2017$prcp_inches)

#median number of sports balls in a dumpster in 2016
trash_wheel %>% 
  group_by(year) %>% 
  summarise(
    sports_balls = median(sports_balls),
    glass_bottles = mean(glass_bottles),
    plastic_bottles = mean(plastic_bottles),
    polystyrene = mean(polystyrene), 
    chip_bags = mean(chip_bags))
```

### Problem 3

Load BRFSS dataset
```{r, collapse=TRUE}
library(p8105.datasets)

data(brfss_smart2010)
```

Clean BRFSS dataset
```{r}
brfss = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  select(-class, -topic, -question, -sample_size, -c(confidence_limit_low:geo_location)) %>% 
  separate(locationdesc, into = c("rem1", "county"), sep = 5) %>% 
  select(-rem1) %>% 
  rename(state = locationabbr) %>% 
  spread(key = response, value = data_value) %>%
  janitor::clean_names() %>% 
  select(year, state, county, poor, fair, good, very_good, excellent) %>% 
  arrange(year, state, county) %>% 
  mutate(verygood_or_excellent = excellent + very_good)
```

#### BRFSS Observations

1. BRFSS dataset represents `r brfss %>% distinct(county, state) %>% nrow()` distinct locations
2. Including the District of Columbia and 50 states, there are `r brfss %>% distinct(state) %>% nrow()`
3. NJ was the most observed state, with 146 observations
4. In 2002, the median proportion of "excellent" responses across all surveyed counties was 23.60

```{r, collapse=TRUE}
#1. 404 unique locations in dataset
brfss %>% 
  distinct(county, state) %>% 
  nrow()

#2. number of states represented & DC = 51
brfss %>% 
  distinct(state) %>% 
  nrow()

#3. state observed the most
plyr::count(brfss$state) %>% 
  arrange(desc(freq)) %>% 
  head(1)

#4. median of the "excellent" proportion in 2002
brfss %>% 
  group_by(year) %>% 
  summarise(excellent = median(excellent, na.rm = TRUE)) %>% 
  arrange(year) %>% 
  head(1)
```

Histogram characterizes the distribution of excellent response proportions across counties that participated in the 2002 health status survey. 
```{r, message=FALSE, warning=FALSE}
#5. histogram of excellent response values in the year 2002
brfss_2002 = brfss %>% 
  filter(year == 2002) 

ggplot(brfss_2002, aes(x = excellent)) +
  geom_histogram() + 
  labs(
    title = "Distribution of Excellent Response Proportions in 2002",
    x = "Proportion of 'Excellent' Responses",
    y = "Number of Counties")
```

Scatterplot characterizes the proportion of "excellent" responses in New York County and Queens County from 2002 to 2010.
```{r}
#6. scatterplot showing proportion of "excellent" response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010
brfss %>% 
  filter(county == "New York County" | county == "Queens County") %>% 
  ggplot(aes(x = year, y = excellent, color = county)) + 
  geom_point(size = 3) +
  labs(
    title = "Proportion of Excellent Responses by Year",
    x = "Year",
    y = "Proportion of Excellent Responses") +
  theme(legend.position = "bottom") +
  viridis::scale_color_viridis(
    name = "County", 
    discrete = TRUE)
```


